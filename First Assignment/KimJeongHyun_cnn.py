# -*- coding: utf-8 -*-
"""KimJeongHyun_cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_cJ6eA7DEuiFxzcxWPm8JIypwdiwCTmG
"""

# Nerual Networks (신경망)
# 신경망은 torch.nn 패키지에서 사용할 수 있다
# nn.Module은 convoultion layer, fully connected layer와 forward로 이루어져 있는데 
# forward는 input을 입력해 output을 산출하는 순전파 함수를 의미한다
#---------------------------------------------------------------------
# 본 예제는 간단한 feed-forward network로, 입력값이 여러 layer를 거쳐 출력값을 리턴한다
# 이러한 신경망의 전형적인 훈련방식은 다음과 같은데
# - learnable한 파라미터(가중치를 말함)들로 구성된 신경망을 정의하고
# - 신경망에 값을 입력하여 결과를 보고
# - 해당 결과로 변환되면서 발생한 loss를 계산하고
# - 역전파(출력에서 입력으로 역추정하는 방식)를 수행하고
# - 신경망의 가중치를 업데이트한다. (가중치 = 가중치 - learning_rate * 기울기)

import torch
import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
  def __init__(self):
    #자식 클래스에서 부모클래스의 내용을 사용할 수 있게 함
    #왜? PyTorch의 기능들을 이용하기 위해서는 __init__()과 forward()를 override해야 함
    super(Net, self).__init__()

    # 입력이미지의 크기(차원) = 32x32
    # 입력이미지 채널 = 1
    # 출력 채널 = 6
    # convolution layer 변환을 위한 kernel 크기 = 3x3 
    #kernel
    #Conv2d는 2차원 convolution layer를 의미, 각 인자는 (입력 채널, 출력 채널, 커널 사이즈)
    self.conv1 = nn.Conv2d(1, 6, 3) # 1개 채널의 이미지를 받고 6개의 채널로 확장
    self.conv2 = nn.Conv2d(6, 16, 3)# 6개 채널의 이미지를 받고 16개의 채널로 확장

    #어파인 변환: y = Wx + b
    #fc는 fully connected layer를 의미
    #Linear는 선형변환함수(y = Wx + b), 각 인자는 (입력 feature, 출력 feature) 
    # - feature? : 딥러닝, 머신러닝에서는 input 변수를 feature라 함
    self.fc1 = nn.Linear(16 * 6 * 6, 120) # 16*6*6개 데이터 -> 120개 데이터로 변환
                              # 이 때 6 * 6은 이미지 차원에서 도출
                              # 레이어의 최종 크기: [{(32 + 2*0 - 3)/1 + 1} + 2*0 - 3]/1 + 1 = 6
                              # 32는 이미지의 가로(=세로)값, 0은 zero padding의 크기, 3은 kernel의 크기
    self.fc2 = nn.Linear(120, 84) # 120 -> 84
    self.fc3 = nn.Linear(84, 10)  # 84 -> 10

  #순전파 함수: 입력 레이어에서 출력 레이어까지의 변환을 순서대로 진행하는 함수
  def forward(self, x):
    #1. 첫번째 convolution layer에 입력이미지 삽입 후 relu 변환
    #   변환 값을 (2, 2) 크기로 max pooling하는데 2차원이므로 max_pool2d 함수 사용
    #   (2, 2)크기로 max pooling한다는 것은 4개(2*2)의 값중 최댓값을 하나의 값으로 전달함을 의미
    #   따라서 이는 곳 convolution된 layer의 W, H를 각각 반으로 줄이는 결과를 낳음
    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
    
    #2. 1의 값을 두번째 convolution layer에 삽입 후 relu 변환
    #   pooling의 윈도우가 정방형이기 때문에 숫자 하나만 써도 무방하다
    x = F.max_pool2d(F.relu(self.conv2(x)), 2)
    
    #3. Full connection을 위해 일렬로 데이터를 펴는(직렬화?) 작업을 수행
    x = x.view(-1, self.num_flat_features(x))
    
    #4. 최종 출력값을 위한 연산 진행
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = self.fc3(x)

    #5.최종 출력값 리턴
    return x

  def num_flat_features(self, x):
    size = x.size()[1:] # 배치차원(첫(0)번째 차원)을 제외한 모든 차원의 크기
    num_features = 1
    for s in size:
      num_features *= s
    return num_features

net = Net()
print(net)

#net의 learnable 파라미터를 조회하는 params 변수
params = list(net.parameters())
print(len(params))
print(params[0].size()) #params[0]이므로 conv1의 가중치를 확인할 수 있다 / conv2의 가중치는 params[2]

#input 이미지 삽입 - 4차원 1x1x32x32 크기 (사실상 2차원에서 32x32 크기) 
input = torch.randn(1, 1, 32, 32)
out = net(input)
print(out)

net.zero_grad()
out.backward(torch.randn(1, 10))

output = net(input)
target = torch.randn(10) # 더미 타겟변수
target = target.view(1, -1) # 출력값과 같은 형태로 변환 (1x10)

# 손실 = 출력(output)과 타겟(target)의 유사도(얼마나 떨어져 있는지) 추정
criterion = nn.MSELoss() #Mean Square Error Loss(단순 오차 함수): 입력과 타겟의 평균 제곱 오차 계산
loss = criterion(output, target)

print(loss)

net.zero_grad() # 모든 파라미터의 기울기 버퍼(?)를 0으로 초기화
print('conv1.bias.grad before backward')
print(net.conv1.bias.grad)

#가중치 업데이트
loss.backward()
print('conv1.bias.grad after backward')
print(net.conv1.bias.grad)