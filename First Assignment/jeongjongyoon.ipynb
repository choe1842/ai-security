{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "jeongjongyoon.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeongjongyoon/ai-security-1/blob/master/First%20Assignment/jeongjongyoon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS9_8rb0EQFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCpGlDWKEQFe",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Classifying Names with a Character-Level RNN\n",
        "*********************************************\n",
        "**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n",
        "\n",
        "We will be building and training a basic character-level RNN to classify\n",
        "words. A character-level RNN reads words as a series of characters -\n",
        "outputting a prediction and \"hidden state\" at each step, feeding its\n",
        "previous hidden state into each next step. We take the final prediction\n",
        "to be the output, i.e. which class the word belongs to.\n",
        "\n",
        "Specifically, we'll train on a few thousand surnames from 18 languages\n",
        "of origin, and predict which language a name is from based on the\n",
        "spelling:\n",
        "\n",
        "::\n",
        "\n",
        "    $ python predict.py Hinton\n",
        "    (-0.47) Scottish\n",
        "    (-1.52) English\n",
        "    (-3.57) Irish\n",
        "\n",
        "    $ python predict.py Schmidhuber\n",
        "    (-0.19) German\n",
        "    (-2.48) Czech\n",
        "    (-2.68) Dutch\n",
        "\n",
        "\n",
        "**Recommended Reading:**\n",
        "\n",
        "I assume you have at least installed PyTorch, know Python, and\n",
        "understand Tensors:\n",
        "\n",
        "-  http://pytorch.org/ For installation instructions\n",
        "-  :doc:`/beginner/deep_learning_60min_blitz` to get started with PyTorch in general\n",
        "-  :doc:`/beginner/pytorch_with_examples` for a wide and deep overview\n",
        "-  :doc:`/beginner/former_torchies_tutorial` if you are former Lua Torch user\n",
        "\n",
        "It would also be useful to know about RNNs and how they work:\n",
        "\n",
        "-  `The Unreasonable Effectiveness of Recurrent Neural\n",
        "   Networks <http://karpathy.github.io/2015/05/21/rnn-effectiveness/>`__\n",
        "   shows a bunch of real life examples\n",
        "-  `Understanding LSTM\n",
        "   Networks <http://colah.github.io/posts/2015-08-Understanding-LSTMs/>`__\n",
        "   is about LSTMs specifically but also informative about RNNs in\n",
        "   general\n",
        "\n",
        "Preparing the Data\n",
        "==================\n",
        "\n",
        ".. Note::\n",
        "   Download the data from\n",
        "   `here <https://download.pytorch.org/tutorial/data.zip>`_\n",
        "   and extract it to the current directory.\n",
        "\n",
        "Included in the ``data/names`` directory are 18 text files named as\n",
        "\"[Language].txt\". Each file contains a bunch of names, one name per\n",
        "line, mostly romanized (but we still need to convert from Unicode to\n",
        "ASCII).\n",
        "\n",
        "We'll end up with a dictionary of lists of names per language,\n",
        "``{language: [names ...]}``. The generic variables \"category\" and \"line\"\n",
        "(for language and name in our case) are used for later extensibility.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fONkADnpEQFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division #python2를 python3처럼 사용하는 모듈\n",
        "from io import open \n",
        "import glob #사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환\n",
        "import os #from os import * 대신에 import os 스타일을 사용해야 os.open() 이 내장 open() 을 가리는 것을 피할 수 있음\n",
        "\n",
        "def findFiles(path): return glob.glob(path) #findFiles 함수 정의\n",
        "\n",
        "print(findFiles('data/names/*.txt')) #data/names 디렉토리에서 txt파일 출력\n",
        "\n",
        "import unicodedata #유니코드 데이터베이스\n",
        "import string #string 모듈\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\" #ascii코드 글자\n",
        "n_letters = len(all_letters) #글자의 길이\n",
        "\n",
        "# 유니코드 문자열을 일반 ASCII로 변환, thanks to http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s): #unicodeToAscii 함수 정의\n",
        "    return ''.join( #텍스트를 AXCII로 변환하는 유니코드 정규화\n",
        "        c for c in unicodedata.normalize('NFD', s) \n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "print(unicodeToAscii('Ślusàrski')) #Ślusàrski를 ASCII 코드로 번역해 출력\n",
        "\n",
        "# 언어별 이름 목록인 category_lines 사전을 만들기\n",
        "category_lines = {} # dictionary : 각 카테고리를 줄(이름)목록에 매핑\n",
        "all_categories = [] # array(언어 목록)\n",
        "\n",
        "# 파일을 읽고 라인으로 분리하기\n",
        "def readLines(filename):  #readLines 함수 정의\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n') #utf-8로 인코딩하여 한글깨짐 해결후 line에 삽입\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "for filename in findFiles('data/names/*.txt'): #filename이 findFiles에 있을때까지\n",
        "    category = os.path.splitext(os.path.basename(filename))[0] #category 사전에 삽입\n",
        "    all_categories.append(category) #all_categories 배열에 추가\n",
        "    lines = readLines(filename) #lines에 readLines 함수 넣기\n",
        "    category_lines[category] = lines #category 크기 만큼 category_lines 배열 만들기\n",
        "\n",
        "n_categories = len(all_categories) #n_categories에 all_categories 길이 삽입"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxI_S3EJEQFh",
        "colab_type": "text"
      },
      "source": [
        "Now we have ``category_lines``, a dictionary mapping each category\n",
        "(language) to a list of lines (names). We also kept track of\n",
        "``all_categories`` (just a list of languages) and ``n_categories`` for\n",
        "later reference.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQg6wp2BEQFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(category_lines['Italian'][:5]) #Italian 사전에 5개 출력"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33grNVaLg5TX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIz0WNnhEQFk",
        "colab_type": "text"
      },
      "source": [
        "Turning Names into Tensors\n",
        "--------------------------\n",
        "\n",
        "Now that we have all the names organized, we need to turn them into\n",
        "Tensors to make any use of them.\n",
        "\n",
        "To represent a single letter, we use a \"one-hot vector\" of size\n",
        "``<1 x n_letters>``. A one-hot vector is filled with 0s except for a 1\n",
        "at index of the current letter, e.g. ``\"b\" = <0 1 0 0 0 ...>``.\n",
        "\n",
        "To make a word we join a bunch of those into a 2D matrix\n",
        "``<line_length x 1 x n_letters>``.\n",
        "\n",
        "That extra 1 dimension is because PyTorch assumes everything is in\n",
        "batches - we're just using a batch size of 1 here.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilolnSJMEQFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "# all_letters로 문자의 주소 찾기, 예시 \"a\"=0\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter) #주소값 반환\n",
        "\n",
        "# 검증을 위해서 한 문자를 <1 x n_letters> tensor로 변환하기\n",
        "def letterToTensor(letter): #글자를 tensor로 변환하기\n",
        "    tensor = torch.zeros(1, n_letters) #주어진 사이즈의 0으로 이루어진 텐서 생성\n",
        "    tensor[0][letterToIndex(letter)] = 1 #one-hot 벡터는 현재 문자의 주소에만 1을 가지고 나머지는 0으로 채워짐\n",
        "    return tensor #tensor 값 반환\n",
        "\n",
        "# 한 줄(이름)을 <line_length x 1 x n_letters>,\n",
        "# 또는 문자 벡터의 어레이로 변경하기\n",
        "def lineToTensor(line):     #line을 tensor로\n",
        "    tensor = torch.zeros(len(line), 1, n_letters) #주어진 사이즈의 0으로 이루어진 tensor 생성\n",
        "    for li, letter in enumerate(line):  #단어를 만들기 위해 one-hot 벡터 묶음을 2차원 행렬에 결합\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "print(letterToTensor('J'))  #J 문자의 주소 찾기\n",
        "\n",
        "print(lineToTensor('Jones').size()) #단어 찾기"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W58NJ7nYEQFn",
        "colab_type": "text"
      },
      "source": [
        "Creating the Network\n",
        "====================\n",
        "\n",
        "Before autograd, creating a recurrent neural network in Torch involved\n",
        "cloning the parameters of a layer over several timesteps. The layers\n",
        "held hidden state and gradients which are now entirely handled by the\n",
        "graph itself. This means you can implement a RNN in a very \"pure\" way,\n",
        "as regular feed-forward layers.\n",
        "\n",
        "This RNN module (mostly copied from `the PyTorch for Torch users\n",
        "tutorial <http://pytorch.org/tutorials/beginner/former_torchies/\n",
        "nn_tutorial.html#example-2-recurrent-net>`__)\n",
        "is just 2 linear layers which operate on an input and hidden state, with\n",
        "a LogSoftmax layer after the output.\n",
        "\n",
        ".. figure:: https://i.imgur.com/Z2xbySO.png\n",
        "   :alt:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGSm5onBEQFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn  #torch.nn 모듈을 가져오고 nn이라 칭함\n",
        "\n",
        "class RNN(nn.Module):   #RNN 클래스를 정의. input 및 hidden state에서 작동하는 2개의 선형 레이어. 출력 후에는 LogSoftMax 레이어가 있음\n",
        "    def __init__(self, input_size, hidden_size, output_size): #초기화 함수 정의\n",
        "        super(RNN, self).__init__() #자식클래스에서 부모클래스(RNN)사용하고 싶은 경우\n",
        "\n",
        "        self.hidden_size = hidden_size #갚 상속 받기\n",
        "#input과 hidden이 결합해 i2o와 i2h로 나옴\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size) \n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1) \n",
        "\n",
        "    def forward(self, input, hidden): #forward 함수 정의\n",
        "        combined = torch.cat((input, hidden), 1) #input과 hidden 결합\n",
        "        hidden = self.i2h(combined) #hidden state에 결합값 넣기\n",
        "        output = self.i2o(combined) #결합한 값 넣기\n",
        "        output = self.softmax(output) #softmax값으로 넣기\n",
        "        return output, hidden # output, hidden 값 출력\n",
        "\n",
        "    def initHidden(self): #Hidden초기화 함수\n",
        "        return torch.zeros(1, self.hidden_size) #hidden_size만큼 텐서 생성\n",
        "\n",
        "n_hidden = 128\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25Hsat7LEQFq",
        "colab_type": "text"
      },
      "source": [
        "To run a step of this network we need to pass an input (in our case, the\n",
        "Tensor for the current letter) and a previous hidden state (which we\n",
        "initialize as zeros at first). We'll get back the output (probability of\n",
        "each language) and a next hidden state (which we keep for the next\n",
        "step).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2ZNBFmjEQFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = letterToTensor('A') #input 값에 A를 tensor로 바꾼 값 삽입\n",
        "hidden =torch.zeros(1, n_hidden) #hidden값에 n_hidden 크기만큼 텐서 생성\n",
        "\n",
        "output, next_hidden = rnn(input, hidden) #이 네트워크의 한 단계를 실행하기 위해 입력과 이전의 hidden state 전달"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kify__GcEQFt",
        "colab_type": "text"
      },
      "source": [
        "For the sake of efficiency we don't want to be creating a new Tensor for\n",
        "every step, so we will use ``lineToTensor`` instead of\n",
        "``letterToTensor`` and use slices. This could be further optimized by\n",
        "pre-computing batches of Tensors.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKbO7D5YEQFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = lineToTensor('Albert') #효율성을 위해서 lineToTensor를 잘라서 사용\n",
        "hidden = torch.zeros(1, n_hidden) #hidden 값에 텐서 생성\n",
        "\n",
        "output, next_hidden = rnn(input[0], hidden) #역시 입력의 0번째 위치 값과 hidden state 전달\n",
        "print(output) #print"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiurmnz8EQFw",
        "colab_type": "text"
      },
      "source": [
        "As you can see the output is a ``<1 x n_categories>`` Tensor, where\n",
        "every item is the likelihood of that category (higher is more likely).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liObT9YQEQFx",
        "colab_type": "text"
      },
      "source": [
        "Training\n",
        "========\n",
        "Preparing for Training\n",
        "----------------------\n",
        "\n",
        "Before going into training we should make a few helper functions. The\n",
        "first is to interpret the output of the network, which we know to be a\n",
        "likelihood of each category. We can use ``Tensor.topk`` to get the index\n",
        "of the greatest value:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Fib2UjKEQFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categoryFromOutput(output): #네트워크를 알고 있는 각 카테고리의 우도로 출력을 해석하기\n",
        "    top_n, top_i = output.topk(1) #value를 기반으로 topK를 뽑아냄\n",
        "    category_i = top_i[0].item()\n",
        "    return all_categories[category_i], category_i #사전과 위치 반환\n",
        "\n",
        "print(categoryFromOutput(output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOsqRa3FEQF1",
        "colab_type": "text"
      },
      "source": [
        "We will also want a quick way to get a training example (a name and its\n",
        "language):\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xadSNuCSEQF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random \n",
        "\n",
        "def randomChoice(l): #randomChoice 함수 정의\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "def randomTrainingExample(): #학습예시를 얻는 빠른 방법\n",
        "    category = randomChoice(all_categories) #category에 랜덤위치 지정\n",
        "    line = randomChoice(category_lines[category]) #line에도 랜덤위치 지정\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "    line_tensor = lineToTensor(line)\n",
        "    return category, line, category_tensor, line_tensor #category, line 값과 위치 반환\n",
        "\n",
        "for i in range(10): #랜덤으로 10개의 언어와 랜덤이름 찾아내기\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    print('category =', category, '/ line =', line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIrHgVrjEQF3",
        "colab_type": "text"
      },
      "source": [
        "Training the Network\n",
        "--------------------\n",
        "\n",
        "Now all it takes to train this network is show it a bunch of examples,\n",
        "have it make guesses, and tell it if it's wrong.\n",
        "\n",
        "For the loss function ``nn.NLLLoss`` is appropriate, since the last\n",
        "layer of the RNN is ``nn.LogSoftmax``.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBmV5dooEQF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss() #RNN의 마지막 레이어가 nn.LogSoftmax이므로 손실함수는 nn.NLLoss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xkw41v_EQF6",
        "colab_type": "text"
      },
      "source": [
        "Each loop of training will:\n",
        "\n",
        "-  Create input and target tensors\n",
        "-  Create a zeroed initial hidden state\n",
        "-  Read each letter in and\n",
        "\n",
        "   -  Keep hidden state for next letter\n",
        "\n",
        "-  Compare final output to target\n",
        "-  Back-propagate\n",
        "-  Return the output and loss\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs_gHSq2EQF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.005 # 너무 높으면 폭발. 너무 낮으면 학습이 안될수도 있음\n",
        "\n",
        "def train(category_tensor, line_tensor): #입력과 목표 tensor\n",
        "    hidden = rnn.initHidden() #초기화된 hidden state\n",
        "\n",
        "    rnn.zero_grad() #rnn을 0으로 만듦\n",
        "\n",
        "    for i in range(line_tensor.size()[0]): #각문자를 읽기\n",
        "        output, hidden = rnn(line_tensor[i], hidden) #다음 문자를 읽기 위한 hidden state 유지\n",
        "\n",
        "    loss = criterion(output, category_tensor) #목표와 출력 비교\n",
        "    loss.backward() #역전파\n",
        "\n",
        "    # learning rate를 곱한 파라미터의 경사도를 파라미터 값에 더함\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(-learning_rate, p.grad.data)\n",
        "\n",
        "    return output, loss.item() #출력과 손실 반환"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vftrIudDEQF9",
        "colab_type": "text"
      },
      "source": [
        "Now we just have to run that with a bunch of examples. Since the\n",
        "``train`` function returns both the output and loss we can print its\n",
        "guesses and also keep track of loss for plotting. Since there are 1000s\n",
        "of examples we print only every ``print_every`` examples, and take an\n",
        "average of the loss.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBtbxm-JEQF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time #time 모듈 import\n",
        "import math #math 모듈 import\n",
        "\n",
        "n_iters = 100000 #값 정의\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "\n",
        "\n",
        "\n",
        "# 도식화를 위한 loss 추적\n",
        "current_loss = 0 #현재 loss\n",
        "all_losses = [] #누적 losses\n",
        "\n",
        "def timeSince(since): #timeSince 함수 정의\n",
        "    now = time.time() #컴퓨터의 현재 시각\n",
        "    s = now - since #시간 구하기\n",
        "    m = math.floor(s / 60) #분 구하기\n",
        "    s -= m * 60 #초 구하기\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "start = time.time() #start값으로 현재 시각 정의\n",
        "\n",
        "for iter in range(1, n_iters + 1):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample() #random학습예시 뽑아내기\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss \n",
        "\n",
        "    # iter 숫자, 손실, 이름, 추측 출력\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category #추측이 맞고 틀릴시 조건 입력\n",
        "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
        "\n",
        "    # 현재 평균 손실을 손실 리스트에 추가\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY1exS4kEQGA",
        "colab_type": "text"
      },
      "source": [
        "Plotting the Results\n",
        "--------------------\n",
        "\n",
        "Plotting the historical loss from ``all_losses`` shows the network\n",
        "learning:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpQjdnNHEQGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt  #matplotlib 이용해 그래프 그리기\n",
        "import matplotlib.ticker as ticker \n",
        "\n",
        "plt.figure() #새로운 figure 생성\n",
        "plt.plot(all_losses) #all_losses의 라인 플롯 생성"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljgfnYtEEQGE",
        "colab_type": "text"
      },
      "source": [
        "Evaluating the Results\n",
        "======================\n",
        "\n",
        "To see how well the network performs on different categories, we will\n",
        "create a confusion matrix, indicating for every actual language (rows)\n",
        "which language the network guesses (columns). To calculate the confusion\n",
        "matrix a bunch of samples are run through the network with\n",
        "``evaluate()``, which is the same as ``train()`` minus the backprop.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRKSSzuMEQGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# confusion matrix에서 정확한 추측을 추정\n",
        "confusion = torch.zeros(n_categories, n_categories)\n",
        "n_confusion = 10000\n",
        "\n",
        "# 주어진 라인의 출력 반환\n",
        "def evaluate(line_tensor): #evaluate로 많은 수의 샘플을 네트워크에 실행\n",
        "    hidden = rnn.initHidden()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    return output #결과 출력\n",
        "\n",
        "# 올바르게 추측된 예시와 기록 살펴보기\n",
        "for i in range(n_confusion): #10000번 동안\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample() #추측 비교\n",
        "    output = evaluate(line_tensor) #결과 비교\n",
        "    guess, guess_i = categoryFromOutput(output)\n",
        "    category_i = all_categories.index(category)\n",
        "    confusion[category_i][guess_i] += 1\n",
        "\n",
        "# 모든 행을 합계로 나눔으로써 정규화하기\n",
        "for i in range(n_categories):\n",
        "    confusion[i] = confusion[i] / confusion[i].sum()\n",
        "\n",
        "# 도식 설정\n",
        "fig = plt.figure() #새로운 figure 생성\n",
        "ax = fig.add_subplot(111) #하나의 figure에 마치 표처럼 여러 axes를 표현가능하게 해줌\n",
        "cax = ax.matshow(confusion.numpy()) #두 축을 같은 축에 표시하기 위해 plt.matshow가 아닌 ax.matshow\n",
        "fig.colorbar(cax) #색깔별 label만들기\n",
        "\n",
        "# 축 설정\n",
        "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
        "ax.set_yticklabels([''] + all_categories)\n",
        "\n",
        "# 모든 tick에서 강제로 레이블 지정\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "# sphinx_gallery_thumbnail_number = 2\n",
        "plt.show() #생성된 모든 figure를 보여줌"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHVWO7d3EQGL",
        "colab_type": "text"
      },
      "source": [
        "You can pick out bright spots off the main axis that show which\n",
        "languages it guesses incorrectly, e.g. Chinese for Korean, and Spanish\n",
        "for Italian. It seems to do very well with Greek, and very poorly with\n",
        "English (perhaps because of overlap with other languages).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3FmqBKrEQGM",
        "colab_type": "text"
      },
      "source": [
        "Running on User Input\n",
        "---------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TnW0bqNEQGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(input_line, n_predictions=3): #predict함수 정의(이름으로 예측보기)\n",
        "    print('\\n> %s' % input_line)\n",
        "    with torch.no_grad(): #기록을 추적하는 것을 방지하기 위해, 코드 블럭을 감쌀 수 있음\n",
        "        output = evaluate(lineToTensor(input_line))\n",
        "\n",
        "        # 최고 N 카테고리 열기\n",
        "        topv, topi = output.topk(n_predictions, 1, True)\n",
        "        predictions = []\n",
        "\n",
        "        for i in range(n_predictions):  #예측범위 내에서\n",
        "            value = topv[0][i].item()  # i번째 값\n",
        "            category_index = topi[0][i].item() #i번째 category_index 삽입\n",
        "            print('(%.2f) %s' % (value, all_categories[category_index])) #결과 출력\n",
        "            predictions.append([value, all_categories[category_index]]) #prediction에 요소 추가\n",
        "\n",
        "predict('Dovesky')\n",
        "predict('Jackson')\n",
        "predict('Satoshi')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuIeD1UcEQGP",
        "colab_type": "text"
      },
      "source": [
        "The final versions of the scripts `in the Practical PyTorch\n",
        "repo <https://github.com/spro/practical-pytorch/tree/master/char-rnn-classification>`__\n",
        "split the above code into a few files:\n",
        "\n",
        "-  ``data.py`` (loads files)\n",
        "-  ``model.py`` (defines the RNN)\n",
        "-  ``train.py`` (runs training)\n",
        "-  ``predict.py`` (runs ``predict()`` with command line arguments)\n",
        "-  ``server.py`` (serve prediction as a JSON API with bottle.py)\n",
        "\n",
        "Run ``train.py`` to train and save the network.\n",
        "\n",
        "Run ``predict.py`` with a name to view predictions:\n",
        "\n",
        "::\n",
        "\n",
        "    $ python predict.py Hazaki\n",
        "    (-0.42) Japanese\n",
        "    (-1.39) Polish\n",
        "    (-3.51) Czech\n",
        "\n",
        "Run ``server.py`` and visit http://localhost:5533/Yourname to get JSON\n",
        "output of predictions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmXClZgbEQGP",
        "colab_type": "text"
      },
      "source": [
        "Exercises\n",
        "=========\n",
        "\n",
        "-  Try with a different dataset of line -> category, for example:\n",
        "\n",
        "   -  Any word -> language\n",
        "   -  First name -> gender\n",
        "   -  Character name -> writer\n",
        "   -  Page title -> blog or subreddit\n",
        "\n",
        "-  Get better results with a bigger and/or better shaped network\n",
        "\n",
        "   -  Add more linear layers\n",
        "   -  Try the ``nn.LSTM`` and ``nn.GRU`` layers\n",
        "   -  Combine multiple of these RNNs as a higher level network\n",
        "\n",
        "\n"
      ]
    }
  ]
}